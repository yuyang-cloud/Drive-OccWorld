# Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models

[![Custom badge](https://img.shields.io/badge/Arxiv-pdf-8A2BE2?logo=arxiv)](https://arxiv.org/abs/2510.16729) ![GitHub license](https://img.shields.io/badge/License-Apache--2.0-red)


> Jianbiao Mei<sup>1,\*</sup>, Yu Yang<sup>1,\*</sup>, Xuemeng Yang<sup>2,‚Ä†</sup>, Licheng Wen<sup>2</sup>, Jiajun Lv<sup>1,‚Ä†</sup>, Botian Shi<sup>2</sup>, Yong Liu<sup>1</sup> <br>
> <sup>1</sup> Zhejiang University &nbsp;&nbsp; <sup>2</sup> Shanghai Artificial Intelligence Laboratory <br>
> <sup>\*</sup> Equal Contribution &nbsp;&nbsp; <sup>‚Ä†</sup> Corresponding Authors



## üéØ Abstract
<div style="text-align:center;">
  <img src="assets/figures/teaser.png" alt="pipeline" width="600">
</div>

End-to-end autonomous driving systems increasingly rely on vision-centric world models to understand and predict their environment. However, a common ineffectiveness in these models is the full reconstruction of future scenes, which expends significant capacity on redundantly modeling static backgrounds. To address this, we propose **IR-WM**, an Implicit Residual World Model that focuses on modeling the current state and evolution of the world. IR-WM first establishes a robust bird's-eye-view representation of the current state from the visual observation. It then leverages the BEV features from the previous timestep as a strong temporal prior and predicts only the "residual", i.e., the changes conditioned on the ego-vehicle's actions and scene context. To alleviate error accumulation over time, we further apply an alignment module to calibrate semantic and dynamic misalignments. Moreover, we investigate different forecasting‚Äìplanning coupling schemes and demonstrate that the implicit future state generated by world models substantially improves planning accuracy. On the nuScenes benchmark, IR-WM achieves top performance in both 4D occupancy forecasting and trajectory planning.


## üìù Getting Started

- [Installation](DOCS/INSTALL.MD) 

- [Prepare Dataset](DOCS/DATASET.MD)

- [Train and Evaluation](DOCS/TRAIN_EVAL.MD)

## üé• Demo of 4D Occupancy and Flow Forecasting

<div style="text-align:center;">
    <video controls width="600px">
        <source src="assets/IR_WM.mp4" type="video/mp4">
        Your browser does not support the video tag.
    </video>
</div>


## Acknowledgments

We utilized the following repos during development:

* [ViDAR](https://github.com/OpenDriveLab/ViDAR)
* [Cam4DOcc](https://github.com/haomo-ai/Cam4DOcc)
* [ST-P3](https://github.com/OpenDriveLab/ST-P3)
* [UniAD](https://github.com/OpenDriveLab/UniAD)

Thanks for their Awesome open-sourced work!

<!-- ## üìÑ License

This project is released under the [Apache 2.0 license](LICENSE).  -->

## üîñ Citation

If you find our project useful, please kindly cite us via:

```bibtext
@article{mei2025vision,
  title={Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models},
  author={Mei, Jianbiao and Yang, Yu and Yang, Xuemeng and Wen, Licheng and Lv, Jiajun and Shi, Botian and Liu, Yong},
  journal={arXiv preprint arXiv:2510.16729},
  year={2025}
}
@article{yang2024driving,
  title={Driving in the occupancy world: Vision-centric 4d occupancy forecasting and planning via world models for autonomous driving},
  author={Yang, Yu and Mei, Jianbiao and Ma, Yukai and Du, Siliang and Chen, Wenqing and Qian, Yijie and Feng, Yuxiang and Liu, Yong},
  journal={arXiv preprint arXiv:2408.14197},
  year={2024}
}